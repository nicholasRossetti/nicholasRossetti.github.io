---
title: "Integrating Classical Planners with GPT-Based Planning Policies"
collection: publications
category: conferences
permalink: 'https://link.springer.com/chapter/10.1007/978-3-031-80607-0_24'
excerpt: 'This paper introduces a neuro-symbolic approach to improve the reliability of PlanGPT, a gpt-2 model trained from scratch for automated planning. While PlanGPT effectively learns general planning policies, it can produces incomplete or invalid plans that violate action preconditions or only partially achieve goals. To address this, we integrate PlanGPT with the symbolic planner LPG. After PlanGPT generates a candidate plan, a validator checks its validity. If the plan is flawed, LPG repairs or completes it, ensuring a correct solution. Our results show significant improvements in the performance of both PlanGPT and LPG, highlighting the effectiveness of combining learning methods with traditional planning techniques. https://link.springer.com/chapter/10.1007/978-3-031-80607-0_24'
date: 2024-11-24
venue: '33th International Conference of the Italian Association for Artificial Intelligence (AIxIA)'
#slidesurl: 'http://academicpages.github.io/files/slides_plangpt_icaps_2024.pdf'
paperurl: 'http://academicpages.github.io/files/paper_plangpt_aixia24.pdf'
citation: 'Integrating Classical Planners with GPT-Based Planning Policies, M. Tummolo, N. Rossetti, AE. Gerevini, M. Olivato, L. Putelli, I. Serina - Proceedings of the 33th International Conference of the Italian Association for Artificial Intelligence (AIxIA), 2024'
---

Recent works on Large Language Models (LLMs) have demonstrated their effectiveness in learning general policies in automated planning. In particular, a system called PlanGPT has achieved impressive performance in terms of coverage in various domains. However, it may produce invalid plans that either satisfy only some goal fluents of the corresponding planning problem or violate the planned actionsâ€™ preconditions. To overcome this limitation, we propose a novel neuro-symbolic approach that combines PlanGPT with a planner capable of repairing (or completing) the plan generated by PlanGPT, thereby leveraging model-based reasoning. When PlanGPT generates a candidate plan for a specific planning problem, we validate it using a symbolic validator. If the generated plan is invalid, we execute the repair procedure of the planner LPG to obtain a valid solution plan from it. In this paper, we empirically evaluate the effectiveness of our approach and demonstrate its performances across various planning domains. Our results show significant improvements in the performance of both PlanGPT and LPG, highlighting the effectiveness of combining learning methods with traditional planning techniques.